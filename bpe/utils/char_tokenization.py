def character_tokenization(corpus: str):
    """
    Tokenize a given text corpus into a list of individual characters.

    Args:
        corpus (str): The input text corpus to tokenize.

    Returns:
        list: A list of individual characters from the corpus.
    """
    return list(corpus)